---
title: "Helping Functions"
execute:
  echo: true
format:
  html:
    code-overflow: wrap
lightbox: true
---

```{python}
#| echo: false
#| output: false

import os
import time
import json

import httpx
from urllib.parse import urlsplit, parse_qsl, urlencode, urlunsplit
import yake
from tqdm import tqdm
import matplotlib.pyplot as plt

API_BASE_URL = "https://api.dp.la/v2/" 
ENV_VAR_NAME = "DPLA_API_KEY" 
FALLBACK_DATA_URL = "https://raw.githubusercontent.com/UCSB-Library-Research-Data-Services/intro2APIs/main/data/" 

api_key = os.getenv("DPLA_API_KEY")
if not api_key:
    api_key = ""

```

One of the most useful features of programming languages is the ability to work with functions: reusable blocks of code that perform a specific task. In Python, functions are defined using the `def` keyword. They can take inputs (arguments) and return outputs (values).

For this exercise, weâ€™ll write a few small helper functions (to avoid repeating ourselves) and two main functions that query the DPLA API and return responses in a clean, â€œPythonicâ€ format.

:::{.callout-tip appearance="simple" collapse="true"}
## You can treat these as â€œgivenâ€
If functions feel a little abstract right now, thatâ€™s completely fine. The main goal of the workshop is learning how to *work with an API* (queries, parameters, and results). You can copy/paste these functions and focus on how you use them.
:::

## Helper functions

These helper functions arenâ€™t strictly necessary, but they keep the rest of the notebook cleaner. You can copy/paste them into your notebook and come back to the details later:

```{python}
def _join_list(x, sep="; ", keep_first_only=False):
    """
    Helper function to join a list of values into a single string. If the input is not a list, it will return the string representation of the input. If the input is None, it will return an empty string.
    """
    if isinstance(x, list):
        if keep_first_only and len(x) > 0:
            return str(x[0])
        return sep.join(str(v) for v in x if v is not None)
    return "" if x is None else str(x)

def top_n(d, n=10):
    """Helper function to return the top n items from a dictionary, sorted by value in descending order."""
    return dict(sorted(d.items(), key=lambda x: x[1], reverse=True)[:n])

def redact_request_url(url):
    """Remove the api_key parameter from the URL for display purposes."""
    parsed_url = urlsplit(str(url))  # Convert httpx.URL to string
    query_params = parse_qsl(parsed_url.query)
    filtered_params = [(name, value) for name, value in query_params if name != "api_key"]
    redacted_query = urlencode(filtered_params)
    redacted_url = parsed_url._replace(query=redacted_query)
    return urlunsplit(redacted_url)
```

## Main functions

Letâ€™s take some time to understand our first main function. The goal is simple: make a DPLA request and get back a JSON response as a Python dictionary.

If we take a look at the [DPLA API documentation](https://pro.dp.la/developers/requests){target="_blank"}, we can see that a request is built from a base URL (`https://api.dp.la/v2`), a resource type (`items` or `collections`), query parameters (e.g. `q=artificial+intelligence`), and your API key.

Additionally, you can request for specific facets (e.g. `facets=sourceResource.type`), specific fields to be returned (e.g. `fields=sourceResource.title,sourceResource.description`), and you can also specify the page number (e.g. `page=2`) and the number of results per page (e.g. `page_size=20`).

If we tried to handle all of that ad hoc every time, our notebook would get long and repetitive fast. Instead, weâ€™ll write one function that builds the request and sends it for us.

Our function will be called `search_items`. It takes a `query`, a `resource_type` (usually `items`), and any additional DPLA parameters via `**parameters`.

Our resulting function will return a dictionary from the JSON response.

```{python}

def search_items(query, resource_type='items', verbose=False, timeout=30.0, **parameters):
    """
    Search DPLA items with given query and parameters.
    
    Args:
        query (str): The search query string. It's possible to use logical operators (AND, OR, NOT). Additionally, you can use wildcards (*) for partial matches.
        resource_type (str): The type of resource to search for. Default is 'items'.
        verbose (bool): If True, prints the request URL. Default is False.
        timeout (float): The timeout for the HTTP request in seconds. Default is 30.0.
        **parameters: Facets and filter parameters from the DPLA API documentation: https://pro.dp.la/developers/requests
                    Dotted keywords and values can be passed using dictionary unpacking. For example, to filter by sourceResource.title, you can pass:
                    **{"sourceResource.title": "example title"}
    Returns:
        dict: The JSON response from the DPLA API as a Python dictionary.
    """
    
    # Build the request URL and minimal parameters
    base_url = f"{API_BASE_URL}{resource_type}"
    params = {
        "q": query,
        "api_key": os.getenv(ENV_VAR_NAME),
    }
    
    # Add additional parameters if any
    for key, value in parameters.items():
        params[key] = value
        
    # Make the request
    with httpx.Client(timeout=timeout) as client:
        response = client.get(base_url, params=params)
    
    if verbose:
        print(f"Request URL [redacted]: {redact_request_url(response.url)}")
    
    response.raise_for_status() 
    return response.json()
```


:::{.callout-note appearance="simple" collapse="false"}
In a proper application, we would want to handle the exceptions that may occur during the request (e.g. network errors, invalid API key, etc.), but for the sake of this exercise we will keep it simple and just raise any exceptions that occur.
:::

Let's test the function with a simple query:

```{python}
response = search_items(
    "artificial AND intelligence",
    page_size=5,
    fields="sourceResource.title,sourceResource.description",
    facets="sourceResource.date.begin,sourceResource.date.end",
    verbose=True
)

print(json.dumps(response, indent=2))
```

Hooray ðŸŽ‰! weâ€™ve successfully queried the DPLA API and got a well-formatted response. However, this function only returns a single page of results. The maximum number of results per page is 100, so if we want more than one page, we need to handle pagination.

Our second function, `search_all_items`, takes almost the same parameters as `search_items`, but it fetches multiple pages and returns a single list of items (up to a maximum you set).

Some specific parameters for this function will allow us to control the maximum number of items to fetch (`max_items`), the sleep time between requests to avoid hitting rate limits (`sleep`), and the timeout for the HTTP requests (`timeout`).

```{python}
def search_all_items(query, resource_type='items', max_items=100, sleep=0.5, verbose=False, timeout=30.0, **parameters):
    """
    Collect up to max_items across pages.
    
    Args:
        query (str): The search query string. It's possible to use logical operators 
            (AND, OR, NOT). Additionally, you can use wildcards (*) for partial matches.
        max_items (int): Maximum number of items to retrieve. For number of elements per page, 
            use the page_size parameter in **parameters.
        sleep (float): Time to wait between requests to avoid hitting rate limits.
        **parameters: Facets and filter parameters from the DPLA API documentation: https://pro.dp.la/developers/requests
    """
    all_docs = []
    page = 1
    page_size = int(parameters.get("page_size", 100))
    if page_size > 100:
        page_size = 100
        print("page_size cannot exceed 100. Setting to 100.")
        
    while len(all_docs) < max_items:
        parameters['page'] = page
        data = search_items(
            query,
            resource_type=resource_type,
            verbose=verbose,
            timeout=timeout,
            **parameters
        )
        docs = data.get('docs', [])
        if not docs:
            break  # No more results
        all_docs.extend(docs)
        
        # stop if we've reached max_items
        if len(all_docs) >= max_items:
            break
        
        page += 1
        time.sleep(sleep)
        
    return all_docs[:max_items]
```

Again, this function can be improved with proper error handling and a better pagination logic, but we want to keep it simple for now. 

Same as with the previous function, we can test it with a simple query:

```{python}
results = search_all_items(
    "artificial AND intelligence",
    page_size=50,
    max_items=150,
    fields="sourceResource.title,sourceResource.description",
    facets="sourceResource.date.begin,sourceResource.date.end",
)

print(f"Total items retrieved: {len(results)}")
print(json.dumps(results[-5:], indent=2))  # Print the last 5 results
```

Great! We have successfully retrieved multiple pages of results from the DPLA API, and we can control the number of items we want to fetch with the `max_items` parameter. Now we are ready to do some queries and explore the data!
