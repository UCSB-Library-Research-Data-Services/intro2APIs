{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce4ae857",
   "metadata": {},
   "source": [
    "WARNING: Don't use the API to download large quantities of data. Use the files available for download instead following these instructions: https://pro.dp.la/developers/bulk-download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9167aa26",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "133b1fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "\n",
    "from getpass import getpass\n",
    "import httpx\n",
    "import re\n",
    "import yake\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb90f76",
   "metadata": {},
   "source": [
    "## Setting up the API key variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21c6dbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL=\"https://api.dp.la/v2/\"\n",
    "ENV_VAR = \"DPLA_API_KEY\"\n",
    "TIMEOUT=30.0\n",
    "FALLBACK_DATA_URL = \"https://raw.githubusercontent.com/UCSB-Library-Research-Data-Services/intro2APIs/refs/heads/main/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc393e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key set in environment variable DPLA_API_KEY.\n"
     ]
    }
   ],
   "source": [
    "key= os.getenv(ENV_VAR)\n",
    "\n",
    "# This method avoids hardcoding the API key in the script\n",
    "# The variable is persistent during the session\n",
    "if not key:\n",
    "    key = getpass(f\"Enter your DPLA API key: \").strip()\n",
    "    if not key:\n",
    "        raise ValueError(\"No API key provided.\")\n",
    "    os.environ[ENV_VAR] = key\n",
    "    \n",
    "print(f\"API key set in environment variable {ENV_VAR}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61724a14",
   "metadata": {},
   "source": [
    "## Helping Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f6fd690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _join_list(x, sep=\"; \", keep_first_only=False):\n",
    "    if isinstance(x, list):\n",
    "        if keep_first_only and len(x) > 0:\n",
    "            return str(x[0])\n",
    "        return sep.join(str(v) for v in x if v is not None)\n",
    "    return \"\" if x is None else str(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca053f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_n(d, n=10):\n",
    "    return dict(sorted(d.items(), key=lambda x: x[1], reverse=True)[:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74a0cdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_items(query, verbose=False, facets=None, **parameters):\n",
    "    \"\"\"\n",
    "    Search DPLA items with given query and parameters.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The search query string. It's possible to use logical operators \n",
    "        (AND, OR, NOT). Additionally, you can use wildcards (*) for partial matches.\n",
    "        **parameters: Facets and filter parameters, such as:\n",
    "            - page_size (int): Number of results per page (default is 10, maximum is 100).\n",
    "            - dataProvider (str): Filter results by one or multiple data provider. \n",
    "                (e.g., \"UC Santa Barbara, Library, Department of Special Research Collections\")\n",
    "            - provider_name (str): Filter results by a specific provider name. \n",
    "                (e.g., \"California Digital Library\")\n",
    "            - resource_type (str): Filter results by item type. Available types are\n",
    "                \"text\", \"image\", \"sound\", \"moving image\", \"physical object\"\n",
    "            - after (str): Filter results with sourceResource.date after the specified date (YYYY-MM-DD).\n",
    "            - before (str): Filter results with sourceResource.date before the specified date (YYYY-MM-DD).\n",
    "            - exact_field_match (str): true or false. \"The exact_field_match behavior is applied to all \n",
    "               specific-field parameters. It does not affect the behavior of the “simple search” q parameter \n",
    "               (which can be combined with fields, and with exact_field_match).\n",
    "            - Other facets and filters as documented in the DPLA API documentation.\n",
    "            \n",
    "    \"\"\"\n",
    "    \n",
    "    base_url = f\"{API_URL}items\"\n",
    "    params = {\n",
    "        \"q\": query,\n",
    "        \"api_key\": os.getenv(ENV_VAR),\n",
    "    }\n",
    "    \n",
    "    # Handle facets\n",
    "    if facets:\n",
    "        params[\"facets\"] = facets\n",
    "    \n",
    "    # Aliases for DPLA parameters\n",
    "    provider_name = parameters.pop(\"provider_name\", None)\n",
    "    if provider_name:\n",
    "        parameters[\"provider.name\"] = provider_name\n",
    "    \n",
    "    after = parameters.pop(\"after\", None)\n",
    "    if after:\n",
    "        parameters[\"sourceResource.date.after\"] = after\n",
    "        \n",
    "    before = parameters.pop(\"before\", None)\n",
    "    if before:\n",
    "        parameters[\"sourceResource.date.before\"] = before\n",
    "        \n",
    "    resource_type = parameters.pop(\"resource_type\", None)\n",
    "    if resource_type:\n",
    "        parameters[\"sourceResource.type\"] = resource_type.lower()\n",
    "    \n",
    "    # Add remaining parameters\n",
    "    for key, value in parameters.items():\n",
    "        params[key] = value\n",
    "        \n",
    "    # Make the request\n",
    "    with httpx.Client(timeout=TIMEOUT) as client:\n",
    "        response = client.get(base_url, params=params)\n",
    "    \n",
    "    print(f\"Request URL: {response.url}\") if verbose else None\n",
    "    \n",
    "    response.raise_for_status() \n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "487aedcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_all_items(query, max_items=100, sleep=0.5, verbose=False, facets=None, **parameters):\n",
    "    \"\"\"\n",
    "    Collect up to max_items across pages.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The search query string. It's possible to use logical operators \n",
    "            (AND, OR, NOT). Additionally, you can use wildcards (*) for partial matches.\n",
    "        max_items (int): Maximum number of items to retrieve. For number of elements per page, \n",
    "            use the page_size parameter in **parameters.\n",
    "        sleep (float): Time to wait between requests to avoid hitting rate limits.\n",
    "        **parameters: Additional facets and filter parameters as documented in the DPLA API documentation.\n",
    "    \"\"\"\n",
    "    all_docs = []\n",
    "    page = 1\n",
    "    page_size = int(parameters.get(\"page_size\", 100))\n",
    "    if page_size > 100:\n",
    "        page_size = 100\n",
    "        print(\"page_size cannot exceed 100. Setting to 100.\")\n",
    "        \n",
    "    while len(all_docs) < max_items:\n",
    "        parameters['page'] = page\n",
    "        data = search_items(query, verbose=verbose, facets=facets, **parameters)\n",
    "        docs = data.get('docs', [])\n",
    "        if not docs:\n",
    "            break  # No more results\n",
    "        all_docs.extend(docs)\n",
    "        \n",
    "        # stop if we've reached max_items\n",
    "        if len(all_docs) >= max_items:\n",
    "            break\n",
    "        \n",
    "        page += 1\n",
    "        time.sleep(sleep)\n",
    "        \n",
    "    return all_docs[:max_items]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4998341d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request URL: https://api.dp.la/v2/items?q=artificial+AND+intelligence&api_key=%3B3oulrgjb%3B1324re&facets=sourceResource.date.begin%2CsourceResource.date.end&page_size=25&page=1\n",
      "HTTP error occurred: Client error '403 Forbidden' for url 'https://api.dp.la/v2/items?q=artificial+AND+intelligence&api_key=%3B3oulrgjb%3B1324re&facets=sourceResource.date.begin%2CsourceResource.date.end&page_size=25&page=1'\n",
      "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403. Using preloaded data instead.\n"
     ]
    },
    {
     "ename": "HTTPStatusError",
     "evalue": "Client error '404 Not Found' for url 'https://raw.githubusercontent.com/UCSB-Library-Research-Data-Services/intro2APIs/main/chapters/preloaded_search_results.json'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPStatusError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 2\u001b[0m     mysearch \u001b[38;5;241m=\u001b[39m \u001b[43msearch_items\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43martificial AND intelligence\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfacets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msourceResource.date.begin,sourceResource.date.end\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpage_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mHTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[0;32mIn[6], line 62\u001b[0m, in \u001b[0;36msearch_items\u001b[0;34m(query, verbose, facets, **parameters)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequest URL: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m~/Workshops/Intro2APIs/.venv/lib/python3.10/site-packages/httpx/_models.py:829\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    828\u001b[0m message \u001b[38;5;241m=\u001b[39m message\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m, error_type\u001b[38;5;241m=\u001b[39merror_type)\n\u001b[0;32m--> 829\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m HTTPStatusError(message, request\u001b[38;5;241m=\u001b[39mrequest, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPStatusError\u001b[0m: Client error '403 Forbidden' for url 'https://api.dp.la/v2/items?q=artificial+AND+intelligence&api_key=%3B3oulrgjb%3B1324re&facets=sourceResource.date.begin%2CsourceResource.date.end&page_size=25&page=1'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/403",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mHTTPStatusError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHTTP error occurred: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Using preloaded data instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m     r \u001b[38;5;241m=\u001b[39m httpx\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/UCSB-Library-Research-Data-Services/intro2APIs/main/chapters/preloaded_search_results.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m     \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     mysearch \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# download the preloaded data for the next steps\u001b[39;00m\n",
      "File \u001b[0;32m~/Workshops/Intro2APIs/.venv/lib/python3.10/site-packages/httpx/_models.py:829\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    827\u001b[0m error_type \u001b[38;5;241m=\u001b[39m error_types\u001b[38;5;241m.\u001b[39mget(status_class, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid status code\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    828\u001b[0m message \u001b[38;5;241m=\u001b[39m message\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m, error_type\u001b[38;5;241m=\u001b[39merror_type)\n\u001b[0;32m--> 829\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m HTTPStatusError(message, request\u001b[38;5;241m=\u001b[39mrequest, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPStatusError\u001b[0m: Client error '404 Not Found' for url 'https://raw.githubusercontent.com/UCSB-Library-Research-Data-Services/intro2APIs/main/chapters/preloaded_search_results.json'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/404"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    mysearch = search_items(\n",
    "        \"artificial AND intelligence\",\n",
    "        facets=\"sourceResource.date.begin,sourceResource.date.end\",\n",
    "        page_size=25,\n",
    "        page=1,\n",
    "        verbose=True\n",
    "        )\n",
    "except httpx.HTTPStatusError as e:\n",
    "    print(f\"HTTP error occurred: {e}. Using preloaded data instead.\")\n",
    "    r = httpx.get(f\"{FALLBACK_DATA_URL}preloaded_search_results.json\")\n",
    "    r.raise_for_status()\n",
    "    mysearch = r.json()\n",
    "    \n",
    "\n",
    "# download the preloaded data for the next steps\n",
    "print(f\"{mysearch.get('count')} results found.\") if isinstance(mysearch, dict) else print(f\"{len(mysearch)} results found.\")\n",
    "print(f\"Facets: {mysearch.get('facets')}\") if isinstance(mysearch, dict) else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3571b1",
   "metadata": {},
   "source": [
    "## Let's play with the faceted elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e380a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the histogram of entries dates\n",
    "\n",
    "facets_list = mysearch.get('facets').get('sourceResource.date.begin').get('entries')\n",
    "\n",
    "years = [d['time'] for d in facets_list][::-1] # We use [::-1] to reverse the order\n",
    "counts = [d['count'] for d in facets_list][::-1]\n",
    "\n",
    "plt.bar(years, counts, color='skyblue', edgecolor='black')\n",
    "\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Items')\n",
    "plt.title('Items about Artificial Intelligence by Year')\n",
    "plt.xticks(range(0, len(years), 5), [years[i] for i in range(0, len(years), 5)], rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41447dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "waves = [\n",
    "    (\"first_wave\", \"1955-1975\"),\n",
    "    (\"second_wave\", \"1990-2005\"),\n",
    "    (\"third_wave\", \"2018-2026\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460afff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pool of results for each period\n",
    "ai_results = {}\n",
    "\n",
    "try:\n",
    "    for period_name, date_range in waves:\n",
    "        print(f\"Searching for AI items in the {period_name}: {date_range}\")\n",
    "        ai_results[period_name] = search_all_items(\n",
    "            \"artificial AND intelligence\",\n",
    "            max_items=3000,\n",
    "            facets=\"sourceResource.date.begin,sourceResource.date.end\",\n",
    "            page_size=50,\n",
    "            after=date_range.split('-')[0],\n",
    "            before=date_range.split('-')[1],\n",
    "            verbose=True\n",
    "        )\n",
    "        print(f\"Found {len(ai_results[period_name])} items for period {period_name}.\\n\")\n",
    "except httpx.HTTPStatusError as e:\n",
    "    print(f\"HTTP error occurred: {e}. Using preloaded data instead.\")\n",
    "    r = httpx.get(f\"{FALLBACK_DATA_URL}ai_results_by_wave.json\")\n",
    "    r.raise_for_status()\n",
    "    ai_results = r.json()\n",
    "    for period_name in ai_results:\n",
    "        print(f\"Loaded {len(ai_results[period_name])} items for period {period_name} from preloaded data.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6c0491",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_results_summary = {period: len(items) for period, items in ai_results.items()}\n",
    "print(\"AI Results Summary by Period:\")\n",
    "for period, count in ai_results_summary.items():\n",
    "    print(f\"{period}: {count} items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfb54d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_results['first_wave'][400].get('sourceResource')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939ac5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_results['first_wave'][400].get('sourceResource').get('subject')[1].get('name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e869ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "## subject pools\n",
    "\n",
    "ai_subjects = {}\n",
    "\n",
    "for period, items in ai_results.items():\n",
    "    subjects = {}\n",
    "    for item in items:\n",
    "        source_res = item.get('sourceResource', {})\n",
    "        item_subjects = source_res.get('subject', [])\n",
    "        for subj in item_subjects:\n",
    "            name = subj.get('name')\n",
    "            terms = re.split(r'[^\\w\\s]+', name) if name else []\n",
    "            for term in terms:\n",
    "                if term is not None and term.strip() != \"\":\n",
    "                    term = term.strip().lower()\n",
    "                    subjects[term] = subjects.get(term, 0) + 1\n",
    "    ai_subjects[period] = subjects\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862f1bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top five subjects per period\n",
    "\n",
    "top = 10\n",
    "\n",
    "for period, subjects in ai_subjects.items():\n",
    "    sorted_subjects = sorted(subjects.items(), key=lambda x: x[1], reverse=True)[:top]\n",
    "    print(f\"Top {top} subjects for {period}:\")\n",
    "    for subj, count in sorted_subjects:\n",
    "        print(f\"  {subj}: {count}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ceea882",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharex=False)\n",
    "\n",
    "for ax, (key, title) in zip(axes, waves):\n",
    "    data = top_n(ai_subjects[key], 10)\n",
    "    terms = list(data.keys())[::-1]\n",
    "    counts = list(data.values())[::-1]\n",
    "\n",
    "    ax.barh(terms, counts)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Frequency\")\n",
    "\n",
    "plt.suptitle(\"How 'Artificial Intelligence' appears across time in DPLA\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41b71b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_keywords = {}\n",
    "\n",
    "kw_extractor = yake.KeywordExtractor(lan=\"en\", n=2, top=5)\n",
    "\n",
    "for period, items in ai_results.items():\n",
    "    period_keywords = {}\n",
    "    for item in items:\n",
    "        source_res = item.get('sourceResource', {})\n",
    "        title = _join_list(source_res.get('title', ''), keep_first_only=True)\n",
    "        description = _join_list(source_res.get('description', ''), keep_first_only=True)\n",
    "        text = f\"{title} {description}\".lower()\n",
    "        \n",
    "        keywords = kw_extractor.extract_keywords(text)\n",
    "        for kw, score in keywords:\n",
    "            period_keywords[kw] = period_keywords.get(kw, 0) + 1\n",
    "            \n",
    "    ai_keywords[period] = period_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101f65d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "top = 10\n",
    "\n",
    "for period, keywords in ai_keywords.items():\n",
    "    sorted_keywords = sorted(keywords.items(), key=lambda x: x[1], reverse=True)[:top]\n",
    "    print(f\"Top {top} keywords for {period}:\")\n",
    "    for kw, count in sorted_keywords:\n",
    "        print(f\"  {kw}: {count}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e3cc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharex=False)\n",
    "\n",
    "waves = [\n",
    "    (\"first_wave\", \"1955–1975\"),\n",
    "    (\"second_wave\", \"1990–2005\"),\n",
    "    (\"third_wave\", \"2018–2026\"),\n",
    "]\n",
    "\n",
    "for ax, (key, title) in zip(axes, waves):\n",
    "    data = top_n(ai_keywords[key], 10)\n",
    "    terms = list(data.keys())[::-1]\n",
    "    counts = list(data.values())[::-1]\n",
    "\n",
    "    ax.barh(terms, counts)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Frequency\")\n",
    "\n",
    "plt.suptitle(\"How 'Artificial Intelligence' appears across time in DPLA\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658b1006",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
